{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JqwvMjTzRQaN",
        "outputId": "d541a8e0-dee2-40a5-e545-47d9d93e0fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkqRKgAYAUj2",
        "outputId": "1c92294b-8096-4c69-9a2b-ba9a71e8ab7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "target_val_acc=0.9940"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyCwGOX3z3m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip  -q '/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/train.csv.zip' -d '/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/train.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d9l8TI5bAZd8",
        "colab": {}
      },
      "source": [
        "# input image dimensions.\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/train.csv')\n",
        "x_train_df = df.drop(['label'], 1, inplace=False)\n",
        "y_train_df = df['label']\n",
        "\n",
        "x_train = np.array(x_train_df.values.flatten()).reshape(len(x_train_df), img_rows, img_cols, 1)\n",
        "y_train = y_train_df.tolist()\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwn2L8rAVXMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da6c51a7-eb5e-48a7-8909-8777a485437c"
      },
      "source": [
        "print(input_shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCaI1817AiKJ",
        "outputId": "a50cb954-de15-4938-a294-aa363f5a5ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Normalization.\n",
        "x_train = x_train.astype('float32')\n",
        "x_train/= 255\n",
        "print('Original dataset:')\n",
        "print('x_train shape:', x_train.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset:\n",
            "x_train shape: (42000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U8bgOtwrAlkc",
        "outputId": "c922c534-982d-4269-af8f-fd1b2f703a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Generates augmented images from the x_train images \n",
        "#array (and uses corresponding y_train labels ofc).\n",
        "datagen = ImageDataGenerator(rotation_range=20,\n",
        "                            width_shift_range=0.10,\n",
        "                            height_shift_range=0.10,\n",
        "                            zoom_range=[0.8, 1.2],\n",
        "                            shear_range=0.2)\n",
        "\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#Appends augmented images to the original x_train and y_train arrays.\n",
        "\n",
        "deg=1            #deg controls the extent of the augmentation. 1 indicates\n",
        "                 #whole 42k images will be yielded in batches and used for\n",
        "                 #training hence increasing train set to ~84k images.\n",
        "\n",
        "print(\"Pre-processing images for data augmentation...Wait a minute...\")\n",
        "\n",
        "iterate=(int)((42000/batch_size)*deg)\n",
        "\n",
        "for i in range(0,iterate):\n",
        "    ret=train_gen.next()  \n",
        "    x_train=np.append(x_train,ret[0],axis=0)\n",
        "    y_train=np.append(y_train,ret[1])\n",
        "\n",
        "print(\"Done adding!\")\n",
        "print(x_train.shape[0], 'Total samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-processing images for data augmentation...Wait a minute...\n",
            "Done adding!\n",
            "83984 Total samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIemywjB4lff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a76d4447-24ce-4040-fb44-95d45cc72600"
      },
      "source": [
        "x_val = x_train[:23984,:,:,:]\n",
        "x_train = x_train[23984:,:,:,:]\n",
        "y_val = y_train[:23984]\n",
        "y_train = y_train[23984:]\n",
        "print(x_train.shape[0], 'Train samples')\n",
        "print(x_val.shape[0], 'val samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 Train samples\n",
            "23984 val samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BpoweYtCEc-",
        "colab": {}
      },
      "source": [
        "#Convert labels to one-hot\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGZ2wj1nCJgc",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 40:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * np.exp(0.1 * (40 - epoch))\n",
        "\n",
        "#Callback for lr updation and stop training \n",
        "class myCallback(keras.callbacks.LearningRateScheduler):\n",
        "    def __init__(self, schedule, val_target):\n",
        "        super(myCallback, self).__init__(schedule)     \n",
        "        self.val_target=val_target\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        try:\n",
        "            if logs.get('val_acc')>=self.val_target:\n",
        "                self.model.stop_training = True\n",
        "                print('Stopped training as target val_acc reached!')\n",
        "            else:\n",
        "                lr_=float(keras.backend.get_value(self.model.optimizer.lr))\n",
        "                print('lr: ','{:.8f}'.format(lr_)) \n",
        "        except:\n",
        "                lr_=float(keras.backend.get_value(self.model.optimizer.lr))\n",
        "                print('lr: ','{:.8f}'.format(lr_)) \n",
        "\n",
        "    \n",
        "callback0 = myCallback(scheduler,target_val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I2pCOV9pCNm3",
        "outputId": "3b33805f-a9c7-488c-fd50-20d88efe5501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(8, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(14, (3, 3),activation='relu'))\n",
        "model.add(Conv2D(14, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(14, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Training\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[callback0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 8)         584       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 22, 22, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 14)          1022      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 14)          1778      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 14)          1778      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 14)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 14)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 56)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1824      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 7,980\n",
            "Trainable params: 7,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 60000 samples, validate on 23984 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 1.1560 - accuracy: 0.6119 - val_loss: 0.4254 - val_accuracy: 0.9343\n",
            "lr:  0.00100000\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.5394 - accuracy: 0.8353 - val_loss: 0.2378 - val_accuracy: 0.9628\n",
            "lr:  0.00100000\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.4062 - accuracy: 0.8795 - val_loss: 0.1675 - val_accuracy: 0.9719\n",
            "lr:  0.00100000\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.3407 - accuracy: 0.9003 - val_loss: 0.1466 - val_accuracy: 0.9716\n",
            "lr:  0.00100000\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.3002 - accuracy: 0.9133 - val_loss: 0.1261 - val_accuracy: 0.9764\n",
            "lr:  0.00100000\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.2726 - accuracy: 0.9217 - val_loss: 0.1049 - val_accuracy: 0.9779\n",
            "lr:  0.00100000\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.2473 - accuracy: 0.9282 - val_loss: 0.0984 - val_accuracy: 0.9757\n",
            "lr:  0.00100000\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.2304 - accuracy: 0.9340 - val_loss: 0.0944 - val_accuracy: 0.9819\n",
            "lr:  0.00100000\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.2169 - accuracy: 0.9388 - val_loss: 0.0902 - val_accuracy: 0.9801\n",
            "lr:  0.00100000\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.2022 - accuracy: 0.9436 - val_loss: 0.0813 - val_accuracy: 0.9789\n",
            "lr:  0.00100000\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1997 - accuracy: 0.9440 - val_loss: 0.0756 - val_accuracy: 0.9831\n",
            "lr:  0.00100000\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1844 - accuracy: 0.9479 - val_loss: 0.0742 - val_accuracy: 0.9829\n",
            "lr:  0.00100000\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.1789 - accuracy: 0.9502 - val_loss: 0.0651 - val_accuracy: 0.9846\n",
            "lr:  0.00100000\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1721 - accuracy: 0.9522 - val_loss: 0.0697 - val_accuracy: 0.9845\n",
            "lr:  0.00100000\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1668 - accuracy: 0.9539 - val_loss: 0.0757 - val_accuracy: 0.9807\n",
            "lr:  0.00100000\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1582 - accuracy: 0.9568 - val_loss: 0.0593 - val_accuracy: 0.9865\n",
            "lr:  0.00100000\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1568 - accuracy: 0.9574 - val_loss: 0.0528 - val_accuracy: 0.9868\n",
            "lr:  0.00100000\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1529 - accuracy: 0.9579 - val_loss: 0.0621 - val_accuracy: 0.9842\n",
            "lr:  0.00100000\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1498 - accuracy: 0.9594 - val_loss: 0.0662 - val_accuracy: 0.9833\n",
            "lr:  0.00100000\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1441 - accuracy: 0.9603 - val_loss: 0.0542 - val_accuracy: 0.9873\n",
            "lr:  0.00100000\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1407 - accuracy: 0.9615 - val_loss: 0.0612 - val_accuracy: 0.9835\n",
            "lr:  0.00100000\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1364 - accuracy: 0.9617 - val_loss: 0.0606 - val_accuracy: 0.9842\n",
            "lr:  0.00100000\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1387 - accuracy: 0.9621 - val_loss: 0.0460 - val_accuracy: 0.9892\n",
            "lr:  0.00100000\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1352 - accuracy: 0.9624 - val_loss: 0.0495 - val_accuracy: 0.9868\n",
            "lr:  0.00100000\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1314 - accuracy: 0.9643 - val_loss: 0.0491 - val_accuracy: 0.9861\n",
            "lr:  0.00100000\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1312 - accuracy: 0.9644 - val_loss: 0.0531 - val_accuracy: 0.9858\n",
            "lr:  0.00100000\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.1282 - accuracy: 0.9642 - val_loss: 0.0461 - val_accuracy: 0.9885\n",
            "lr:  0.00100000\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.1290 - accuracy: 0.9645 - val_loss: 0.0425 - val_accuracy: 0.9882\n",
            "lr:  0.00100000\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1255 - accuracy: 0.9650 - val_loss: 0.0420 - val_accuracy: 0.9882\n",
            "lr:  0.00100000\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1240 - accuracy: 0.9658 - val_loss: 0.0419 - val_accuracy: 0.9890\n",
            "lr:  0.00100000\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1192 - accuracy: 0.9669 - val_loss: 0.0413 - val_accuracy: 0.9890\n",
            "lr:  0.00100000\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1248 - accuracy: 0.9662 - val_loss: 0.0428 - val_accuracy: 0.9885\n",
            "lr:  0.00100000\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1205 - accuracy: 0.9671 - val_loss: 0.0460 - val_accuracy: 0.9885\n",
            "lr:  0.00100000\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1185 - accuracy: 0.9670 - val_loss: 0.0422 - val_accuracy: 0.9890\n",
            "lr:  0.00100000\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1179 - accuracy: 0.9680 - val_loss: 0.0445 - val_accuracy: 0.9877\n",
            "lr:  0.00100000\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1144 - accuracy: 0.9678 - val_loss: 0.0437 - val_accuracy: 0.9887\n",
            "lr:  0.00100000\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.1127 - accuracy: 0.9689 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
            "lr:  0.00100000\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1138 - accuracy: 0.9687 - val_loss: 0.0371 - val_accuracy: 0.9903\n",
            "lr:  0.00100000\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.1074 - accuracy: 0.9701 - val_loss: 0.0474 - val_accuracy: 0.9868\n",
            "lr:  0.00100000\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1079 - accuracy: 0.9705 - val_loss: 0.0421 - val_accuracy: 0.9894\n",
            "lr:  0.00100000\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1099 - accuracy: 0.9696 - val_loss: 0.0480 - val_accuracy: 0.9857\n",
            "lr:  0.00100000\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1070 - accuracy: 0.9710 - val_loss: 0.0399 - val_accuracy: 0.9890\n",
            "lr:  0.00090484\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1056 - accuracy: 0.9713 - val_loss: 0.0439 - val_accuracy: 0.9880\n",
            "lr:  0.00081873\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 0.0339 - val_accuracy: 0.9901\n",
            "lr:  0.00074082\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0957 - accuracy: 0.9735 - val_loss: 0.0399 - val_accuracy: 0.9887\n",
            "lr:  0.00067032\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0975 - accuracy: 0.9728 - val_loss: 0.0382 - val_accuracy: 0.9895\n",
            "lr:  0.00060653\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0932 - accuracy: 0.9742 - val_loss: 0.0329 - val_accuracy: 0.9906\n",
            "lr:  0.00054881\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0901 - accuracy: 0.9755 - val_loss: 0.0324 - val_accuracy: 0.9909\n",
            "lr:  0.00049659\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0885 - accuracy: 0.9760 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
            "lr:  0.00044933\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0870 - accuracy: 0.9760 - val_loss: 0.0327 - val_accuracy: 0.9910\n",
            "lr:  0.00040657\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0832 - accuracy: 0.9773 - val_loss: 0.0308 - val_accuracy: 0.9913\n",
            "lr:  0.00036788\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0820 - accuracy: 0.9767 - val_loss: 0.0345 - val_accuracy: 0.9899\n",
            "lr:  0.00033287\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0827 - accuracy: 0.9773 - val_loss: 0.0302 - val_accuracy: 0.9914\n",
            "lr:  0.00030119\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0846 - accuracy: 0.9762 - val_loss: 0.0304 - val_accuracy: 0.9913\n",
            "lr:  0.00027253\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0797 - accuracy: 0.9777 - val_loss: 0.0299 - val_accuracy: 0.9913\n",
            "lr:  0.00024660\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0803 - accuracy: 0.9776 - val_loss: 0.0308 - val_accuracy: 0.9911\n",
            "lr:  0.00022313\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0785 - accuracy: 0.9781 - val_loss: 0.0315 - val_accuracy: 0.9908\n",
            "lr:  0.00020190\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0754 - accuracy: 0.9791 - val_loss: 0.0299 - val_accuracy: 0.9909\n",
            "lr:  0.00018268\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0753 - accuracy: 0.9792 - val_loss: 0.0302 - val_accuracy: 0.9912\n",
            "lr:  0.00016530\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.0290 - val_accuracy: 0.9916\n",
            "lr:  0.00014957\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0761 - accuracy: 0.9792 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "lr:  0.00013534\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0720 - accuracy: 0.9804 - val_loss: 0.0296 - val_accuracy: 0.9916\n",
            "lr:  0.00012246\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0733 - accuracy: 0.9798 - val_loss: 0.0297 - val_accuracy: 0.9920\n",
            "lr:  0.00011080\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0737 - accuracy: 0.9800 - val_loss: 0.0296 - val_accuracy: 0.9914\n",
            "lr:  0.00010026\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.0711 - accuracy: 0.9797 - val_loss: 0.0287 - val_accuracy: 0.9914\n",
            "lr:  0.00009072\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.0697 - accuracy: 0.9805 - val_loss: 0.0292 - val_accuracy: 0.9912\n",
            "lr:  0.00008208\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0707 - accuracy: 0.9798 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
            "lr:  0.00007427\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0707 - accuracy: 0.9805 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
            "lr:  0.00006721\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0685 - accuracy: 0.9813 - val_loss: 0.0294 - val_accuracy: 0.9914\n",
            "lr:  0.00006081\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0700 - accuracy: 0.9809 - val_loss: 0.0285 - val_accuracy: 0.9917\n",
            "lr:  0.00005502\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0692 - accuracy: 0.9802 - val_loss: 0.0287 - val_accuracy: 0.9914\n",
            "lr:  0.00004979\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0692 - accuracy: 0.9809 - val_loss: 0.0293 - val_accuracy: 0.9916\n",
            "lr:  0.00004505\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0687 - accuracy: 0.9805 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
            "lr:  0.00004076\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0731 - accuracy: 0.9797 - val_loss: 0.0277 - val_accuracy: 0.9921\n",
            "lr:  0.00003688\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0664 - accuracy: 0.9817 - val_loss: 0.0290 - val_accuracy: 0.9915\n",
            "lr:  0.00003337\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0704 - accuracy: 0.9809 - val_loss: 0.0289 - val_accuracy: 0.9916\n",
            "lr:  0.00003020\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0712 - accuracy: 0.9804 - val_loss: 0.0284 - val_accuracy: 0.9917\n",
            "lr:  0.00002732\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0679 - accuracy: 0.9807 - val_loss: 0.0283 - val_accuracy: 0.9920\n",
            "lr:  0.00002472\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0681 - accuracy: 0.9815 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
            "lr:  0.00002237\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0670 - accuracy: 0.9813 - val_loss: 0.0282 - val_accuracy: 0.9919\n",
            "lr:  0.00002024\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0286 - val_accuracy: 0.9916\n",
            "lr:  0.00001832\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
            "lr:  0.00001657\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0678 - accuracy: 0.9813 - val_loss: 0.0285 - val_accuracy: 0.9918\n",
            "lr:  0.00001500\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0663 - accuracy: 0.9814 - val_loss: 0.0281 - val_accuracy: 0.9919\n",
            "lr:  0.00001357\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.0280 - val_accuracy: 0.9919\n",
            "lr:  0.00001228\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0682 - accuracy: 0.9807 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
            "lr:  0.00001111\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0673 - accuracy: 0.9805 - val_loss: 0.0280 - val_accuracy: 0.9918\n",
            "lr:  0.00001005\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0667 - accuracy: 0.9814 - val_loss: 0.0283 - val_accuracy: 0.9917\n",
            "lr:  0.00000910\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0694 - accuracy: 0.9802 - val_loss: 0.0282 - val_accuracy: 0.9917\n",
            "lr:  0.00000823\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0684 - accuracy: 0.9808 - val_loss: 0.0283 - val_accuracy: 0.9917\n",
            "lr:  0.00000745\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0681 - accuracy: 0.9813 - val_loss: 0.0280 - val_accuracy: 0.9918\n",
            "lr:  0.00000674\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0668 - accuracy: 0.9818 - val_loss: 0.0277 - val_accuracy: 0.9919\n",
            "lr:  0.00000610\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0709 - accuracy: 0.9803 - val_loss: 0.0280 - val_accuracy: 0.9918\n",
            "lr:  0.00000552\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.0280 - val_accuracy: 0.9918\n",
            "lr:  0.00000499\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 0.0281 - val_accuracy: 0.9917\n",
            "lr:  0.00000452\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.0281 - val_accuracy: 0.9917\n",
            "lr:  0.00000409\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0686 - accuracy: 0.9811 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
            "lr:  0.00000370\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
            "lr:  0.00000335\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0676 - accuracy: 0.9816 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
            "lr:  0.00000303\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0684 - accuracy: 0.9810 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
            "lr:  0.00000274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f376b72ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KmiWss7cCTV_",
        "outputId": "30a20442-9720-44ee-9b76-14270efb0495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#validation Testing\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('val loss:', score[0])\n",
        "print('val accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val loss: 0.027904890140992594\n",
            "val accuracy: 0.9918279051780701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4DMd-Wt5l4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.predict(x_test,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijhm3d67-6my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/test.csv')\n",
        "df=df.astype('float32')/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh7LuZYK-rdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54dfe06e-1173-43b7-cd42-c7d3acba3585"
      },
      "source": [
        "x_test = np.array(df.values.flatten()).reshape(len(df), img_rows, img_cols,1)\n",
        "t=model.predict_classes(x_test,verbose=1)\n",
        "t"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 2s 75us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 9, ..., 3, 9, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLa5XRDXERg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfsubmit = pd.read_csv('/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/gs.csv')    \n",
        "dfsubmit['Label']=t\n",
        "dfsubmit\n",
        "dfsubmit.to_csv('/content/drive/My Drive/ML Enthusiasts/Vidit/codeML/MNIST/result.csv',header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}